{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7599b20c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " No GPU detected. Running on CPU.\n",
      "  For GPU support, install: pip install tensorflow[and-cuda]\n",
      "26-01-09 09:16:15 - Directory /home/rama/.deepface has been created\n",
      "26-01-09 09:16:15 - Directory /home/rama/.deepface/weights has been created\n",
      "============================================================\n",
      "   FACE & EMOTION DETECTION - ACCESSIBILITY MODE\n",
      "   Using DeepFace with RetinaFace (High Accuracy)\n",
      "============================================================\n",
      "Detectable emotions: angry, disgust, fear, happy, sad, surprise, neutral\n",
      "Press 'Q' to quit\n",
      "============================================================\n",
      "\n",
      "Initializing... First detection may take a few seconds.\n",
      "\n",
      "\n",
      " Application closed.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@5844.725] global cap_v4l.cpp:914 open VIDEOIO(V4L2:/dev/video0): can't open camera by index\n",
      "[ERROR:0@5844.726] global obsensor_uvc_stream_channel.cpp:163 getStreamChannelGroup Camera index out of range\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\" GPU detected and enabled: {gpus}\")\n",
    "    except RuntimeError as e:\n",
    "        print(f\"GPU setup error: {e}\")\n",
    "else:\n",
    "    print(\" No GPU detected. Running on CPU.\")\n",
    "    print(\"  For GPU support, install: pip install tensorflow[and-cuda]\")\n",
    "\n",
    "from deepface import DeepFace\n",
    "\n",
    "EMOTIONS = [\"angry\", \"disgust\", \"fear\", \"happy\", \"sad\", \"surprise\", \"neutral\"]\n",
    "\n",
    "EMOTION_COLORS = {\n",
    "    \"angry\": (0, 0, 255),\n",
    "    \"disgust\": (0, 128, 0),\n",
    "    \"fear\": (128, 0, 128),\n",
    "    \"happy\": (0, 255, 255),\n",
    "    \"sad\": (255, 0, 0),\n",
    "    \"surprise\": (0, 165, 255),\n",
    "    \"neutral\": (200, 200, 200)\n",
    "}\n",
    "\n",
    "emotion_history = deque(maxlen=5)\n",
    "\n",
    "def smooth_emotions(current_emotions):\n",
    "    emotion_history.append(current_emotions)\n",
    "\n",
    "    if len(emotion_history) < 2:\n",
    "        return current_emotions\n",
    "\n",
    "    smoothed = {}\n",
    "    for emotion in EMOTIONS:\n",
    "        values = [h.get(emotion, 0) for h in emotion_history]\n",
    "        smoothed[emotion] = sum(values) / len(values)\n",
    "\n",
    "    return smoothed\n",
    "\n",
    "def draw_rounded_rect(img, pt1, pt2, color, thickness, radius=15):\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "\n",
    "    cv2.line(img, (x1 + radius, y1), (x2 - radius, y1), color, thickness)\n",
    "    cv2.line(img, (x1 + radius, y2), (x2 - radius, y2), color, thickness)\n",
    "    cv2.line(img, (x1, y1 + radius), (x1, y2 - radius), color, thickness)\n",
    "    cv2.line(img, (x2, y1 + radius), (x2, y2 - radius), color, thickness)\n",
    "\n",
    "    cv2.ellipse(img, (x1 + radius, y1 + radius), (radius, radius), 180, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x2 - radius, y1 + radius), (radius, radius), 270, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x1 + radius, y2 - radius), (radius, radius), 90, 0, 90, color, thickness)\n",
    "    cv2.ellipse(img, (x2 - radius, y2 - radius), (radius, radius), 0, 0, 90, color, thickness)\n",
    "\n",
    "def draw_emotion_panel(frame, emotions_dict, x, y):\n",
    "    panel_width = 200\n",
    "    panel_height = 200\n",
    "\n",
    "    overlay = frame.copy()\n",
    "    cv2.rectangle(overlay, (x, y), (x + panel_width, y + panel_height), (30, 30, 30), -1)\n",
    "    cv2.addWeighted(overlay, 0.7, frame, 0.3, 0, frame)\n",
    "\n",
    "    cv2.putText(frame, \"EMOTIONS\", (x + 10, y + 25),cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255, 255, 255), 2)\n",
    "\n",
    "    sorted_emotions = sorted(emotions_dict.items(), key=lambda x: -x[1])\n",
    "\n",
    "    bar_height = 18\n",
    "    bar_max_width = 120\n",
    "    start_y = y + 45\n",
    "\n",
    "    for i, (emotion, score) in enumerate(sorted_emotions):\n",
    "        bar_y = start_y + (i * (bar_height + 6))\n",
    "\n",
    "        cv2.putText(frame, emotion.capitalize()[:3], (x + 10, bar_y + 14),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.45, (180, 180, 180), 1)\n",
    "\n",
    "        cv2.rectangle(frame, (x + 45, bar_y), (x + 45 + bar_max_width, bar_y + bar_height),\n",
    "                      (60, 60, 60), -1)\n",
    "\n",
    "        filled_width = int(bar_max_width * score)\n",
    "        if filled_width > 0:\n",
    "            color = EMOTION_COLORS.get(emotion, (0, 255, 0))\n",
    "            cv2.rectangle(frame, (x + 45, bar_y), (x + 45 + filled_width, bar_y + bar_height),\n",
    "                          color, -1)\n",
    "\n",
    "        cv2.putText(frame, f\"{score:.0%}\", (x + 170, bar_y + 14),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 255, 255), 1)\n",
    "\n",
    "def main():\n",
    "    print(\"=\" * 60)\n",
    "    print(\"   FACE & EMOTION DETECTION - ACCESSIBILITY MODE\")\n",
    "    print(\"   Using DeepFace with RetinaFace (High Accuracy)\")\n",
    "    print(\"=\" * 60)\n",
    "    print(\"Detectable emotions:\", \", \".join(EMOTIONS))\n",
    "    print(\"Press 'Q' to quit\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_WIDTH, 1280)\n",
    "    cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 720)\n",
    "    cap.set(cv2.CAP_PROP_FPS, 30)\n",
    "    cap.set(cv2.CAP_PROP_BUFFERSIZE, 1)\n",
    "\n",
    "    frame_count = 0\n",
    "    analyze_every = 3\n",
    "\n",
    "    last_result = None\n",
    "    last_face_region = None\n",
    "\n",
    "    print(\"\\nInitializing... First detection may take a few seconds.\\n\")\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        frame_count += 1\n",
    "\n",
    "        h, w = frame.shape[:2]\n",
    "\n",
    "        if frame_count % analyze_every == 0:\n",
    "            try:\n",
    "                results = DeepFace.analyze(\n",
    "                    frame,\n",
    "                    actions=['emotion'],\n",
    "                    detector_backend='retinaface',\n",
    "                    enforce_detection=False,\n",
    "                    silent=True\n",
    "                )\n",
    "\n",
    "                if results and isinstance(results, list):\n",
    "                    last_result = results[0]\n",
    "                    last_face_region = last_result.get('region', None)\n",
    "                elif results and isinstance(results, dict):\n",
    "                    last_result = results\n",
    "                    last_face_region = last_result.get('region', None)\n",
    "\n",
    "            except Exception as e:\n",
    "                try:\n",
    "                    results = DeepFace.analyze(\n",
    "                        frame,\n",
    "                        actions=['emotion'],\n",
    "                        detector_backend='opencv',\n",
    "                        enforce_detection=False,\n",
    "                        silent=True\n",
    "                    )\n",
    "                    if results:\n",
    "                        last_result = results[0] if isinstance(results, list) else results\n",
    "                        last_face_region = last_result.get('region', None)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "        if last_result and last_face_region:\n",
    "            x = last_face_region.get('x', 0)\n",
    "            y_pos = last_face_region.get('y', 0)\n",
    "            face_w = last_face_region.get('w', 100)\n",
    "            face_h = last_face_region.get('h', 100)\n",
    "\n",
    "            emotion_scores = last_result.get('emotion', {})\n",
    "\n",
    "            normalized_scores = {}\n",
    "            for emotion in EMOTIONS:\n",
    "                score = emotion_scores.get(emotion, 0)\n",
    "                normalized_scores[emotion] = score / 100.0 if score > 1 else score\n",
    "\n",
    "            smoothed_scores = smooth_emotions(normalized_scores)\n",
    "\n",
    "            dominant_emotion = max(smoothed_scores.items(), key=lambda x: x[1])\n",
    "            emotion_name, emotion_score = dominant_emotion\n",
    "\n",
    "            box_color = EMOTION_COLORS.get(emotion_name, (0, 255, 0))\n",
    "\n",
    "            padding = 20\n",
    "            x1 = max(0, x - padding)\n",
    "            y1 = max(0, y_pos - padding)\n",
    "            x2 = min(w, x + face_w + padding)\n",
    "            y2 = min(h, y_pos + face_h + padding)\n",
    "\n",
    "            cv2.rectangle(frame, (x1, y1), (x2, y2), box_color, 3)\n",
    "\n",
    "            corner_len = 30\n",
    "            thickness = 5\n",
    "            cv2.line(frame, (x1, y1), (x1 + corner_len, y1), box_color, thickness)\n",
    "            cv2.line(frame, (x1, y1), (x1, y1 + corner_len), box_color, thickness)\n",
    "            cv2.line(frame, (x2, y1), (x2 - corner_len, y1), box_color, thickness)\n",
    "            cv2.line(frame, (x2, y1), (x2, y1 + corner_len), box_color, thickness)\n",
    "            cv2.line(frame, (x1, y2), (x1 + corner_len, y2), box_color, thickness)\n",
    "            cv2.line(frame, (x1, y2), (x1, y2 - corner_len), box_color, thickness)\n",
    "            cv2.line(frame, (x2, y2), (x2 - corner_len, y2), box_color, thickness)\n",
    "            cv2.line(frame, (x2, y2), (x2, y2 - corner_len), box_color, thickness)\n",
    "\n",
    "            label = f\"{emotion_name.upper()} {emotion_score:.0%}\"\n",
    "            label_size = cv2.getTextSize(label, cv2.FONT_HERSHEY_SIMPLEX, 1.2, 3)[0]\n",
    "\n",
    "            label_x = x1\n",
    "            label_y = y1 - 15\n",
    "\n",
    "            cv2.rectangle(frame,\n",
    "                          (label_x - 5, label_y - label_size[1] - 10),\n",
    "                          (label_x + label_size[0] + 10, label_y + 5),\n",
    "                          box_color, -1)\n",
    "\n",
    "            cv2.putText(frame, label, (label_x, label_y),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1.2, (0, 0, 0), 3)\n",
    "\n",
    "            panel_x = min(x2 + 30, w - 220)\n",
    "            panel_y = max(y1, 10)\n",
    "            draw_emotion_panel(frame, smoothed_scores, panel_x, panel_y)\n",
    "\n",
    "        else:\n",
    "            warning_text = \"Looking for face... Please face the camera\"\n",
    "            text_size = cv2.getTextSize(warning_text, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]\n",
    "            text_x = (w - text_size[0]) // 2\n",
    "\n",
    "            cv2.rectangle(frame, (text_x - 10, 30), (text_x + text_size[0] + 10, 70), (0, 0, 150), -1)\n",
    "            cv2.putText(frame, warning_text, (text_x, 55),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 255, 255), 2)\n",
    "\n",
    "        info_text = \"Press 'Q' to quit | DeepFace + RetinaFace | High Accuracy Mode\"\n",
    "        cv2.putText(frame, info_text, (10, h - 15),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, (150, 150, 150), 1)\n",
    "\n",
    "        cv2.imshow(\"Face & Emotion Detection - Accessibility\", frame)\n",
    "\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "        if key == ord('q') or key == ord('Q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    print(\"\\n Application closed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "penv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
